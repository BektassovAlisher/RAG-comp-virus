{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "document = \"doc/virus-book.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characteristics of a Virus\n",
      "Viruses have four essential\n",
      "characteristics.\n",
      "SELF REPLICATION : First, viruses are\n",
      "notable for the ability to replicate itself\n",
      "to infect computers , much like its\n",
      "biological counterpart. By replicating\n",
      "itself it is able to spread across\n",
      "computer systems and networks to\n",
      "infect as much as it possibly can.\n"
     ]
    }
   ],
   "source": [
    "from langchain.retrievers import ParentDocumentRetriever\n",
    "from langchain.storage import InMemoryStore\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(document)\n",
    "doc = loader.load(\n",
    ")\n",
    "\n",
    "child_splitter = RecursiveCharacterTextSplitter(chunk_size = 200)\n",
    "parent_splitter = RecursiveCharacterTextSplitter(chunk_size = 1000)\n",
    "\n",
    "embeddings = OllamaEmbeddings(model = \"embeddinggemma:latest\")\n",
    "\n",
    "storage = InMemoryStore()\n",
    "\n",
    "vectorstore = Chroma(embedding_function=embeddings)\n",
    "\n",
    "parent_retriever = ParentDocumentRetriever(\n",
    "    vectorstore=vectorstore,\n",
    "    docstore=storage,\n",
    "    child_splitter=child_splitter,\n",
    "    parent_splitter=parent_splitter,\n",
    ")\n",
    "\n",
    "parent_retriever.add_documents(doc)\n",
    "\n",
    "result = parent_retriever.invoke(\"Characteristics of a Virus\")\n",
    "print(result[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characteristics of a Virus\n",
      "Viruses have four essential\n",
      "characteristics.\n",
      "SELF REPLICATION : First, viruses are\n",
      "notable for the ability to replicate itself\n",
      "to infect computers , much like its\n"
     ]
    }
   ],
   "source": [
    "splitter = RecursiveCharacterTextSplitter(chunk_size = 1000)\n",
    "red = splitter.split_documents(doc)\n",
    "\n",
    "lol_vec = Chroma.from_documents(doc, embeddings)\n",
    "\n",
    "res2 = lol_vec.similarity_search(\"Characteristics of a Virus\")\n",
    "print(res2[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- РЕЗУЛЬТАТ: ТОЛЬКО HyDE (Chunk 200) ---\n",
      "Characteristics of a Virus\n",
      "Viruses have four essential\n",
      "characteristics.\n",
      "SELF REPLICATION : First, viruses are\n",
      "notable for the ability to replicate itself\n",
      "to infect computers , much like its\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.chains import HypotheticalDocumentEmbedder\n",
    "\n",
    "# 1. Настройка моделей\n",
    "llm = Ollama(model=\"llama3.2:latest\")\n",
    "base_embeddings = OllamaEmbeddings(model=\"embeddinggemma:latest\")\n",
    "\n",
    "# 2. Настройка HyDE\n",
    "hyde_embeddings = HypotheticalDocumentEmbedder.from_llm(\n",
    "    llm, \n",
    "    base_embeddings, \n",
    "    prompt_key=\"web_search\"\n",
    ")\n",
    "\n",
    "# 3. Обычная нарезка (только 200 символов, без Parent-структуры)\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=200, chunk_overlap=20)\n",
    "chunks = splitter.split_documents(doc) # Твой загруженный документ\n",
    "\n",
    "# 4. Создаем обычную базу с HyDE-эмбеддингами\n",
    "hyde_vectorstore = Chroma.from_documents(chunks, hyde_embeddings)\n",
    "\n",
    "# 5. Поиск\n",
    "query = \"Characteristics of a Virus\"\n",
    "results = hyde_vectorstore.similarity_search(query, k=3)\n",
    "\n",
    "print(\"--- РЕЗУЛЬТАТ: ТОЛЬКО HyDE (Chunk 200) ---\")\n",
    "print(results[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- РЕЗУЛЬТАТ: ТОЛЬКО HyDE (Chunk 200) ---\n",
      "Characteristics of a Virus\n",
      "Viruses have four essential\n",
      "characteristics.\n",
      "SELF REPLICATION : First, viruses are\n",
      "notable for the ability to replicate itself\n",
      "to infect computers , much like its\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.chains import HypotheticalDocumentEmbedder\n",
    "from langchain.retrievers import EnsembleRetriever\n",
    "# 1. Настройка моделей\n",
    "llm = Ollama(model=\"llama3.2:latest\")\n",
    "base_embeddings = OllamaEmbeddings(model=\"embeddinggemma:latest\")\n",
    "\n",
    "# 2. Настройка HyDE\n",
    "hyde_embeddings = HypotheticalDocumentEmbedder.from_llm(\n",
    "    llm, \n",
    "    base_embeddings, \n",
    "    prompt_key=\"web_search\"\n",
    ")\n",
    "\n",
    " # Твой загруженный документ\n",
    "\n",
    "# 4. Создаем обычную базу с HyDE-эмбеддингами\n",
    "\n",
    "\n",
    "child_splitter = RecursiveCharacterTextSplitter(chunk_size = 200)\n",
    "parent_splitter = RecursiveCharacterTextSplitter(chunk_size = 1000)\n",
    "\n",
    "hyde_vectorstore = Chroma(embedding_function=hyde_embeddings)\n",
    "hyde_parent_retriever = ParentDocumentRetriever(\n",
    "    vectorstore=hyde_vectorstore,\n",
    "    docstore=storage,\n",
    "    child_splitter=child_splitter,\n",
    "    parent_splitter=parent_splitter,\n",
    ")\n",
    "\n",
    "# 3. ВТОРОЙ РЕТРИВЕР: Обычные эмбеддинги + Parent (Классический \"Буквальный\")\n",
    "# Используем base_embeddings без HyDE\n",
    "classic_vectorstore = Chroma(embedding_function=base_embeddings)\n",
    "classic_parent_retriever = ParentDocumentRetriever(\n",
    "    vectorstore=classic_vectorstore,\n",
    "    docstore=storage,\n",
    "    child_splitter=child_splitter,\n",
    "    parent_splitter=parent_splitter,\n",
    ")\n",
    "\n",
    "# 4. Добавляем документы в ОБА (чтобы оба проиндексировали текст)\n",
    "hyde_parent_retriever.add_documents(doc)\n",
    "classic_parent_retriever.add_documents(doc)\n",
    "\n",
    "# 5. СОЗДАЕМ АНСАМБЛЬ\n",
    "# weights=[0.4, 0.6] означает, что мы чуть больше доверяем классике, \n",
    "# чтобы не пропускать такие куски как \"Characteristics\"\n",
    "final_retriever = EnsembleRetriever(\n",
    "    retrievers=[hyde_parent_retriever, classic_parent_retriever],\n",
    "    weights=[0.4, 0.6] \n",
    ")\n",
    "\n",
    "# 6. ТЕСТ\n",
    "result = final_retriever.invoke(\"computer virus\")\n",
    "\n",
    "\n",
    "# 5. Поиск\n",
    "query = \"Characteristics of a Virus\"\n",
    "result = parent_retriever.invoke(query)\n",
    "\n",
    "print(\"--- РЕЗУЛЬТАТ: ТОЛЬКО HyDE (Chunk 200) ---\")\n",
    "print(results[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "HYDE + PDR + EMBEDDINGSFILTER COMPRESSOR Когда вопросы задаются простыми словами, а информация в PDF сложная и техническая. Мы используем HyDE для понимания сути и PDR для выдачи полных ответов.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import ParentDocumentRetriever, ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import EmbeddingsFilter\n",
    "from langchain.storage import InMemoryStore\n",
    "from langchain.chains import HypotheticalDocumentEmbedder\n",
    "\n",
    "\n",
    "llm = Ollama(model=\"llama3.2:latest\")\n",
    "base_embeddings = OllamaEmbeddings(model=\"gemma\")\n",
    "\n",
    "hyde_embeddings = HypotheticalDocumentEmbedder(\n",
    "    llm,\n",
    "    base_embeddings,\n",
    "    prompt_key=\"web_search\"\n",
    ")\n",
    "\n",
    "child_splitter = RecursiveCharacterTextSplitter(chunk_size = 200, chunk_overlap=20)\n",
    "parent_splitter = RecursiveCharacterTextSplitter(chunk_size = 1000, chunk_overlap = 100)\n",
    "\n",
    "store = InMemoryStore()\n",
    "vectorstore = Chroma(embedding_function=hyde_embeddings)\n",
    "\n",
    "parent_retriever = ParentDocumentRetriever(\n",
    "    vectorstore=vectorstore,\n",
    "    docstore=storage,\n",
    "    child_splitter=child_splitter,\n",
    "    parent_splitter=parent_splitter\n",
    ")\n",
    "\n",
    "parent_retriever.add_documents(doc)\n",
    "\n",
    "\n",
    "compressor = EmbeddingsFilter(embeddings=base_embeddings, similarity_threshold=0.75)\n",
    "\n",
    "compressor_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor,\n",
    "    base_retriever=parent_retriever\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Максимальная чистота\" (PDR + Ensemble + LLM Compressor)\n",
    "Для чего: Это \"тяжелая артиллерия\". Используем ансамбль для поиска, а потом просим LLM вырезать из длинных документов PDR только самое важное."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers.document_compressors import LLMChainExtractor\n",
    "\n",
    "# 1. Базовый ретривер - Ансамбль (уже созданный ранее)\n",
    "base_retriever = EnsembleRetriever(\n",
    "    retrievers=[pdr_retriever, bm25_retriever],\n",
    "    weights=[0.5, 0.5]\n",
    ")\n",
    "\n",
    "# 2. Умный компрессор (LLMChainExtractor)\n",
    "# Он прочитает найденные куски и удалит из них лишний текст (воду)\n",
    "smart_compressor = LLMChainExtractor.from_llm(llm)\n",
    "\n",
    "# 3. Финальный пайплайн\n",
    "super_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=smart_compressor,\n",
    "    base_retriever=base_retriever\n",
    ")\n",
    "\n",
    "# Ответ будет очень коротким, точным и без лишнего мусора\n",
    "clean_context = super_retriever.invoke(\"Какие 4 характеристики у вирусов?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Буквальный и Смысловой Гибрид\" (Hybrid + Ensemble)\n",
    "Для чего: Чтобы находить и точные термины (как \"XJ-99\"), и общие понятия. Здесь мы объединяем классический поиск (BM25) и векторный."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import BM25Retriever, EnsembleRetriever\n",
    "\n",
    "# 1. Ретривер для точных слов (Sparse)\n",
    "bm25_retriever = BM25Retriever.from_documents(child_chunks)\n",
    "bm25_retriever.k = 3\n",
    "\n",
    "# 2. Ретривер для смысла (Dense)\n",
    "vector_retriever = Chroma(embedding_function=base_embeddings).as_retriever(search_kwargs={\"k\": 3})\n",
    "\n",
    "# 3. Ансамбль (Hybrid Search)\n",
    "# Даем 70% веса смыслу и 30% точным словам\n",
    "hybrid_ensemble = EnsembleRetriever(\n",
    "    retrievers=[bm25_retriever, vector_retriever],\n",
    "    weights=[0.3, 0.7]\n",
    ")\n",
    "\n",
    "# 4. Проверка\n",
    "# Найдет \"вирус XJ-99\" даже если векторная модель не знает такого названия\n",
    "results = hybrid_ensemble.invoke(\"расскажи про вирус XJ-99\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
